


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.modules.tensordict_module.actors &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  main (0.4.0 )
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
      <li>torchrl.modules.tensordict_module.actors</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <div class="pytorch-call-to-action-links">
            <div id="tutorial-type">_modules/torchrl/modules/tensordict_module/actors</div>

            <div id="google-colab-link">
              <img class="call-to-action-img" src="../../../../_static/images/pytorch-colab.svg"/>
              <div class="call-to-action-desktop-view">Run in Google Colab</div>
              <div class="call-to-action-mobile-view">Colab</div>
            </div>
            <div id="download-notebook-link">
              <img class="call-to-action-notebook-img" src="../../../../_static/images/pytorch-download.svg"/>
              <div class="call-to-action-desktop-view">Download Notebook</div>
              <div class="call-to-action-mobile-view">Notebook</div>
            </div>
            <div id="github-view-link">
              <img class="call-to-action-img" src="../../../../_static/images/pytorch-github.svg"/>
              <div class="call-to-action-desktop-view">View on GitHub</div>
              <div class="call-to-action-mobile-view">GitHub</div>
            </div>
          </div>

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchrl.modules.tensordict_module.actors</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">tensordict</span> <span class="kn">import</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">unravel_key</span>
<span class="kn">from</span> <span class="nn">tensordict.nn</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">dispatch</span><span class="p">,</span>
    <span class="n">TensorDictModule</span><span class="p">,</span>
    <span class="n">TensorDictModuleBase</span><span class="p">,</span>
    <span class="n">TensorDictModuleWrapper</span><span class="p">,</span>
    <span class="n">TensorDictSequential</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensordict.utils</span> <span class="kn">import</span> <span class="n">NestedKey</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Categorical</span>

<span class="kn">from</span> <span class="nn">torchrl.data.tensor_specs</span> <span class="kn">import</span> <span class="n">CompositeSpec</span><span class="p">,</span> <span class="n">TensorSpec</span>
<span class="kn">from</span> <span class="nn">torchrl.data.utils</span> <span class="kn">import</span> <span class="n">_process_action_space_spec</span>
<span class="kn">from</span> <span class="nn">torchrl.modules.models.models</span> <span class="kn">import</span> <span class="n">DistributionalDQNnet</span>
<span class="kn">from</span> <span class="nn">torchrl.modules.tensordict_module.common</span> <span class="kn">import</span> <span class="n">SafeModule</span>
<span class="kn">from</span> <span class="nn">torchrl.modules.tensordict_module.probabilistic</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">SafeProbabilisticModule</span><span class="p">,</span>
    <span class="n">SafeProbabilisticTensorDictSequential</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torchrl.modules.tensordict_module.sequence</span> <span class="kn">import</span> <span class="n">SafeSequential</span>


<div class="viewcode-block" id="Actor"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.Actor.html#torchrl.modules.Actor">[docs]</a><span class="k">class</span> <span class="nc">Actor</span><span class="p">(</span><span class="n">SafeModule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;General class for deterministic actors in RL.</span>

<span class="sd">    The Actor class comes with default values for the out_keys ([&quot;action&quot;])</span>
<span class="sd">    and if the spec is provided but not as a CompositeSpec object, it will be</span>
<span class="sd">    automatically translated into :obj:`spec = CompositeSpec(action=spec)`</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module): a :class:`torch.nn.Module` used to map the input to</span>
<span class="sd">            the output parameter space.</span>
<span class="sd">        in_keys (iterable of str, optional): keys to be read from input</span>
<span class="sd">            tensordict and passed to the module. If it</span>
<span class="sd">            contains more than one element, the values will be passed in the</span>
<span class="sd">            order given by the in_keys iterable.</span>
<span class="sd">            Defaults to ``[&quot;observation&quot;]``.</span>
<span class="sd">        out_keys (iterable of str): keys to be written to the input tensordict.</span>
<span class="sd">            The length of out_keys must match the</span>
<span class="sd">            number of tensors returned by the embedded module. Using &quot;_&quot; as a</span>
<span class="sd">            key avoid writing tensor to output.</span>
<span class="sd">            Defaults to ``[&quot;action&quot;]``.</span>
<span class="sd">        spec (TensorSpec, optional): Keyword-only argument.</span>
<span class="sd">            Specs of the output tensor. If the module</span>
<span class="sd">            outputs multiple output tensors,</span>
<span class="sd">            spec characterize the space of the first output tensor.</span>
<span class="sd">        safe (bool): Keyword-only argument.</span>
<span class="sd">            If ``True``, the value of the output is checked against the</span>
<span class="sd">            input spec. Out-of-domain sampling can</span>
<span class="sd">            occur because of exploration policies or numerical under/overflow</span>
<span class="sd">            issues. If this value is out of bounds, it is projected back onto the</span>
<span class="sd">            desired space using the :obj:`TensorSpec.project`</span>
<span class="sd">            method. Default is ``False``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import UnboundedContinuousTensorSpec</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import Actor</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(3, 4)}, [3,])</span>
<span class="sd">        &gt;&gt;&gt; action_spec = UnboundedContinuousTensorSpec(4)</span>
<span class="sd">        &gt;&gt;&gt; module = torch.nn.Linear(4, 4)</span>
<span class="sd">        &gt;&gt;&gt; td_module = Actor(</span>
<span class="sd">        ...    module=module,</span>
<span class="sd">        ...    spec=action_spec,</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; td_module(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;action&quot;))</span>
<span class="sd">        tensor([[-1.3635, -0.0340,  0.1476, -1.3911],</span>
<span class="sd">                [-0.1664,  0.5455,  0.2247, -0.4583],</span>
<span class="sd">                [-0.2916,  0.2160,  0.5337, -0.5193]], grad_fn=&lt;AddmmBackward0&gt;)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorSpec</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="s2">&quot;action&quot;</span> <span class="ow">in</span> <span class="n">out_keys</span>
            <span class="ow">and</span> <span class="n">spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">CompositeSpec</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">CompositeSpec</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="n">spec</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">module</span><span class="p">,</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">spec</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="ProbabilisticActor"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor.html#torchrl.modules.ProbabilisticActor">[docs]</a><span class="k">class</span> <span class="nc">ProbabilisticActor</span><span class="p">(</span><span class="n">SafeProbabilisticTensorDictSequential</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;General class for probabilistic actors in RL.</span>

<span class="sd">    The Actor class comes with default values for the out_keys ([&quot;action&quot;])</span>
<span class="sd">    and if the spec is provided but not as a CompositeSpec object, it will be</span>
<span class="sd">    automatically translated into :obj:`spec = CompositeSpec(action=spec)`</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module): a :class:`torch.nn.Module` used to map the input to</span>
<span class="sd">            the output parameter space.</span>
<span class="sd">        in_keys (str or iterable of str or dict): key(s) that will be read from the</span>
<span class="sd">            input TensorDict and used to build the distribution. Importantly, if it&#39;s an</span>
<span class="sd">            iterable of string or a string, those keys must match the keywords used by</span>
<span class="sd">            the distribution class of interest, e.g. :obj:`&quot;loc&quot;` and :obj:`&quot;scale&quot;` for</span>
<span class="sd">            the Normal distribution and similar. If in_keys is a dictionary,, the keys</span>
<span class="sd">            are the keys of the distribution and the values are the keys in the</span>
<span class="sd">            tensordict that will get match to the corresponding distribution keys.</span>
<span class="sd">        out_keys (str or iterable of str): keys where the sampled values will be</span>
<span class="sd">            written. Importantly, if these keys are found in the input TensorDict, the</span>
<span class="sd">            sampling step will be skipped.</span>
<span class="sd">        spec (TensorSpec, optional): keyword-only argument containing the specs</span>
<span class="sd">            of the output tensor. If the module outputs multiple output tensors,</span>
<span class="sd">            spec characterize the space of the first output tensor.</span>
<span class="sd">        safe (bool): keyword-only argument. if ``True``, the value of the output is checked against the</span>
<span class="sd">            input spec. Out-of-domain sampling can</span>
<span class="sd">            occur because of exploration policies or numerical under/overflow</span>
<span class="sd">            issues. If this value is out of bounds, it is projected back onto the</span>
<span class="sd">            desired space using the :obj:`TensorSpec.project`</span>
<span class="sd">            method. Default is ``False``.</span>
<span class="sd">        default_interaction_type=InteractionType.RANDOM (str, optional): keyword-only argument.</span>
<span class="sd">            Default method to be used to retrieve</span>
<span class="sd">            the output value. Should be one of: &#39;mode&#39;, &#39;median&#39;, &#39;mean&#39; or &#39;random&#39;</span>
<span class="sd">            (in which case the value is sampled randomly from the distribution). Default</span>
<span class="sd">            is &#39;mode&#39;.</span>
<span class="sd">            Note: When a sample is drawn, the :obj:`ProbabilisticTDModule` instance will</span>
<span class="sd">            first look for the interaction mode dictated by the `interaction_typ()`</span>
<span class="sd">            global function. If this returns `None` (its default value), then the</span>
<span class="sd">            `default_interaction_type` of the `ProbabilisticTDModule` instance will be</span>
<span class="sd">            used. Note that DataCollector instances will use `set_interaction_type` to</span>
<span class="sd">            :class:`tensordict.nn.InteractionType.RANDOM` by default.</span>
<span class="sd">        distribution_class (Type, optional): keyword-only argument.</span>
<span class="sd">            A :class:`torch.distributions.Distribution` class to</span>
<span class="sd">            be used for sampling.</span>
<span class="sd">            Default is :class:`tensordict.nn.distributions.Delta`.</span>
<span class="sd">        distribution_kwargs (dict, optional): keyword-only argument.</span>
<span class="sd">            Keyword-argument pairs to be passed to the distribution.</span>
<span class="sd">        return_log_prob (bool, optional): keyword-only argument.</span>
<span class="sd">            If ``True``, the log-probability of the</span>
<span class="sd">            distribution sample will be written in the tensordict with the key</span>
<span class="sd">            `&#39;sample_log_prob&#39;`. Default is ``False``.</span>
<span class="sd">        cache_dist (bool, optional): keyword-only argument.</span>
<span class="sd">            EXPERIMENTAL: if ``True``, the parameters of the</span>
<span class="sd">            distribution (i.e. the output of the module) will be written to the</span>
<span class="sd">            tensordict along with the sample. Those parameters can be used to re-compute</span>
<span class="sd">            the original distribution later on (e.g. to compute the divergence between</span>
<span class="sd">            the distribution used to sample the action and the updated distribution in</span>
<span class="sd">            PPO). Default is ``False``.</span>
<span class="sd">        n_empirical_estimate (int, optional): keyword-only argument.</span>
<span class="sd">            Number of samples to compute the empirical</span>
<span class="sd">            mean when it is not available. Defaults to 1000.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import BoundedTensorSpec</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import ProbabilisticActor, NormalParamWrapper, TanhNormal</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(3, 4)}, [3,])</span>
<span class="sd">        &gt;&gt;&gt; action_spec = BoundedTensorSpec(shape=torch.Size([4]),</span>
<span class="sd">        ...    low=-1, high=1)</span>
<span class="sd">        &gt;&gt;&gt; module = NormalParamWrapper(torch.nn.Linear(4, 8))</span>
<span class="sd">        &gt;&gt;&gt; tensordict_module = TensorDictModule(module, in_keys=[&quot;observation&quot;], out_keys=[&quot;loc&quot;, &quot;scale&quot;])</span>
<span class="sd">        &gt;&gt;&gt; td_module = ProbabilisticActor(</span>
<span class="sd">        ...    module=tensordict_module,</span>
<span class="sd">        ...    spec=action_spec,</span>
<span class="sd">        ...    in_keys=[&quot;loc&quot;, &quot;scale&quot;],</span>
<span class="sd">        ...    distribution_class=TanhNormal,</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; params = TensorDict.from_module(td_module)</span>
<span class="sd">        &gt;&gt;&gt; with params.to_module(td_module):</span>
<span class="sd">        ...     td = td_module(td)</span>
<span class="sd">        &gt;&gt;&gt; td</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    Probabilistic actors also support compound actions through the</span>
<span class="sd">    :class:`tensordict.nn.CompositeDistribution` class. This distribution takes</span>
<span class="sd">    a tensordict as input (typically `&quot;params&quot;`) and reads it as a whole: the</span>
<span class="sd">    content of this tensordict is the input to the distributions contained in the</span>
<span class="sd">    compound one.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import CompositeDistribution, TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import ProbabilisticActor</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn, distributions as d</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; class Module(nn.Module):</span>
<span class="sd">        ...     def forward(self, x):</span>
<span class="sd">        ...         return x[..., :3], x[..., 3:6], x[..., 6:]</span>
<span class="sd">        &gt;&gt;&gt; module = TensorDictModule(Module(),</span>
<span class="sd">        ...                           in_keys=[&quot;x&quot;],</span>
<span class="sd">        ...                           out_keys=[(&quot;params&quot;, &quot;normal&quot;, &quot;loc&quot;),</span>
<span class="sd">        ...                              (&quot;params&quot;, &quot;normal&quot;, &quot;scale&quot;),</span>
<span class="sd">        ...                              (&quot;params&quot;, &quot;categ&quot;, &quot;logits&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; actor = ProbabilisticActor(module,</span>
<span class="sd">        ...                            in_keys=[&quot;params&quot;],</span>
<span class="sd">        ...                            distribution_class=CompositeDistribution,</span>
<span class="sd">        ...                            distribution_kwargs={&quot;distribution_map&quot;: {</span>
<span class="sd">        ...                                 &quot;normal&quot;: d.Normal, &quot;categ&quot;: d.Categorical}}</span>
<span class="sd">        ...                           )</span>
<span class="sd">        &gt;&gt;&gt; data = TensorDict({&quot;x&quot;: torch.rand(10)}, [])</span>
<span class="sd">        &gt;&gt;&gt; actor(data)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                categ: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                normal: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                params: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        categ: TensorDict(</span>
<span class="sd">                            fields={</span>
<span class="sd">                                logits: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                            batch_size=torch.Size([]),</span>
<span class="sd">                            device=None,</span>
<span class="sd">                            is_shared=False),</span>
<span class="sd">                        normal: TensorDict(</span>
<span class="sd">                            fields={</span>
<span class="sd">                                loc: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                                scale: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                            batch_size=torch.Size([]),</span>
<span class="sd">                            device=None,</span>
<span class="sd">                            is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([]),</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                x: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]],</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorSpec</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">out_keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="ow">and</span> <span class="n">spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">CompositeSpec</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">CompositeSpec</span><span class="p">({</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">spec</span><span class="p">})</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">module</span><span class="p">,</span>
            <span class="n">SafeProbabilisticModule</span><span class="p">(</span>
                <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span> <span class="n">spec</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">),</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="ValueOperator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ValueOperator.html#torchrl.modules.ValueOperator">[docs]</a><span class="k">class</span> <span class="nc">ValueOperator</span><span class="p">(</span><span class="n">TensorDictModule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;General class for value functions in RL.</span>

<span class="sd">    The ValueOperator class comes with default values for the in_keys and</span>
<span class="sd">    out_keys arguments ([&quot;observation&quot;] and [&quot;state_value&quot;] or</span>
<span class="sd">    [&quot;state_action_value&quot;], respectively and depending on whether the &quot;action&quot;</span>
<span class="sd">    key is part of the in_keys list).</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module): a :class:`torch.nn.Module` used to map the input to</span>
<span class="sd">            the output parameter space.</span>
<span class="sd">        in_keys (iterable of str, optional): keys to be read from input</span>
<span class="sd">            tensordict and passed to the module. If it</span>
<span class="sd">            contains more than one element, the values will be passed in the</span>
<span class="sd">            order given by the in_keys iterable.</span>
<span class="sd">            Defaults to ``[&quot;observation&quot;]``.</span>
<span class="sd">        out_keys (iterable of str): keys to be written to the input tensordict.</span>
<span class="sd">            The length of out_keys must match the</span>
<span class="sd">            number of tensors returned by the embedded module. Using &quot;_&quot; as a</span>
<span class="sd">            key avoid writing tensor to output.</span>
<span class="sd">            Defaults to ``[&quot;action&quot;]``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import UnboundedContinuousTensorSpec</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import ValueOperator</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(3, 4), &quot;action&quot;: torch.randn(3, 2)}, [3,])</span>
<span class="sd">        &gt;&gt;&gt; class CustomModule(nn.Module):</span>
<span class="sd">        ...     def __init__(self):</span>
<span class="sd">        ...         super().__init__()</span>
<span class="sd">        ...         self.linear = torch.nn.Linear(6, 1)</span>
<span class="sd">        ...     def forward(self, obs, action):</span>
<span class="sd">        ...         return self.linear(torch.cat([obs, action], -1))</span>
<span class="sd">        &gt;&gt;&gt; module = CustomModule()</span>
<span class="sd">        &gt;&gt;&gt; td_module = ValueOperator(</span>
<span class="sd">        ...    in_keys=[&quot;observation&quot;, &quot;action&quot;], module=module</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; params = TensorDict.from_module(td_module)</span>
<span class="sd">        &gt;&gt;&gt; with params.to_module(td_module):</span>
<span class="sd">        ...     td = td_module(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_action_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>


<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">[</span><span class="s2">&quot;state_value&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;action&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">in_keys</span> <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;state_action_value&quot;</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">module</span><span class="o">=</span><span class="n">module</span><span class="p">,</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="QValueModule"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.QValueModule.html#torchrl.modules.QValueModule">[docs]</a><span class="k">class</span> <span class="nc">QValueModule</span><span class="p">(</span><span class="n">TensorDictModuleBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Q-Value TensorDictModule for Q-value policies.</span>

<span class="sd">    This module processes a tensor containing action value into is argmax</span>
<span class="sd">    component (i.e. the resulting greedy action), following a given</span>
<span class="sd">    action space (one-hot, binary or categorical).</span>
<span class="sd">    It works with both tensordict and regular tensors.</span>

<span class="sd">    Args:</span>
<span class="sd">        action_space (str, optional): Action space. Must be one of</span>
<span class="sd">            ``&quot;one-hot&quot;``, ``&quot;mult-one-hot&quot;``, ``&quot;binary&quot;`` or ``&quot;categorical&quot;``.</span>
<span class="sd">            This argument is exclusive with ``spec``, since ``spec``</span>
<span class="sd">            conditions the action_space.</span>
<span class="sd">        action_value_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action value. Defaults to ``&quot;action_value&quot;``.</span>
<span class="sd">        action_mask_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action mask. Defaults to ``&quot;None&quot;`` (equivalent to no masking).</span>
<span class="sd">        out_keys (list of str or tuple of str, optional): The output keys</span>
<span class="sd">            representing the actions, action values and chosen action value.</span>
<span class="sd">            Defaults to ``[&quot;action&quot;, &quot;action_value&quot;, &quot;chosen_action_value&quot;]``.</span>
<span class="sd">        var_nums (int, optional): if ``action_space = &quot;mult-one-hot&quot;``,</span>
<span class="sd">            this value represents the cardinality of each</span>
<span class="sd">            action component.</span>
<span class="sd">        spec (TensorSpec, optional): if provided, the specs of the action (and/or</span>
<span class="sd">            other outputs). This is exclusive with ``action_space``, as the spec</span>
<span class="sd">            conditions the action space.</span>
<span class="sd">        safe (bool): if ``True``, the value of the output is checked against the</span>
<span class="sd">            input spec. Out-of-domain sampling can</span>
<span class="sd">            occur because of exploration policies or numerical under/overflow issues.</span>
<span class="sd">            If this value is out of bounds, it is projected back onto the</span>
<span class="sd">            desired space using the :obj:`TensorSpec.project`</span>
<span class="sd">            method. Default is ``False``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        if the input is a single tensor, a triplet containing the chosen action,</span>
<span class="sd">        the values and the value of the chose action is returned. If a tensordict</span>
<span class="sd">        is provided, it is updated with these entries at the keys indicated by the</span>
<span class="sd">        ``out_keys`` field.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; action_space = &quot;categorical&quot;</span>
<span class="sd">        &gt;&gt;&gt; action_value_key = &quot;my_action_value&quot;</span>
<span class="sd">        &gt;&gt;&gt; actor = QValueModule(action_space, action_value_key=action_value_key)</span>
<span class="sd">        &gt;&gt;&gt; # This module works with both tensordict and regular tensors:</span>
<span class="sd">        &gt;&gt;&gt; value = torch.zeros(4)</span>
<span class="sd">        &gt;&gt;&gt; value[-1] = 1</span>
<span class="sd">        &gt;&gt;&gt; actor(my_action_value=value)</span>
<span class="sd">        (tensor(3), tensor([0., 0., 0., 1.]), tensor([1.]))</span>
<span class="sd">        &gt;&gt;&gt; actor(value)</span>
<span class="sd">        (tensor(3), tensor([0., 0., 0., 1.]), tensor([1.]))</span>
<span class="sd">        &gt;&gt;&gt; actor(TensorDict({action_value_key: value}, []))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                action_value: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                chosen_action_value: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                my_action_value: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">action_value_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_mask_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">var_nums</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorSpec</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">safe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Using specs in action_space will be deprecated in v0.4.0,&quot;</span>
                <span class="s2">&quot; please use the &#39;spec&#39; argument if you want to provide an action spec&quot;</span><span class="p">,</span>
                <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">action_space</span><span class="p">,</span> <span class="n">spec</span> <span class="o">=</span> <span class="n">_process_action_space_spec</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">spec</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_nums</span> <span class="o">=</span> <span class="n">var_nums</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_func_mapping</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;one_hot&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_one_hot</span><span class="p">,</span>
            <span class="s2">&quot;mult_one_hot&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mult_one_hot</span><span class="p">,</span>
            <span class="s2">&quot;binary&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_binary</span><span class="p">,</span>
            <span class="s2">&quot;categorical&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_categorical</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_value_func_mapping</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;categorical&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_action_value</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">action_space</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_func_mapping</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;action_space must be one of </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_func_mapping</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">, got </span><span class="si">{</span><span class="n">action_space</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">action_value_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">action_value_key</span> <span class="o">=</span> <span class="s2">&quot;action_value&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span> <span class="o">=</span> <span class="n">action_mask_key</span>
        <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">action_value_key</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="n">in_keys</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">,</span> <span class="n">action_value_key</span><span class="p">,</span> <span class="s2">&quot;chosen_action_value&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">action_value_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">out_keys</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected the action-value key to be &#39;</span><span class="si">{</span><span class="n">action_value_key</span><span class="si">}</span><span class="s2">&#39; but got </span><span class="si">{</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">=</span> <span class="n">out_keys</span>
        <span class="n">action_key</span> <span class="o">=</span> <span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">CompositeSpec</span><span class="p">):</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">CompositeSpec</span><span class="p">({</span><span class="n">action_key</span><span class="p">:</span> <span class="n">spec</span><span class="p">})</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_spec</span><span class="p">(</span><span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">,</span> <span class="n">spec</span><span class="o">=</span><span class="n">spec</span><span class="p">)</span>

    <span class="n">register_spec</span> <span class="o">=</span> <span class="n">SafeModule</span><span class="o">.</span><span class="n">register_spec</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">spec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CompositeSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span>

    <span class="nd">@spec</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spec</span><span class="p">:</span> <span class="n">CompositeSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">CompositeSpec</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Trying to set an object of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> as a tensorspec but expected a CompositeSpec instance.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span> <span class="o">=</span> <span class="n">spec</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">action_value_key</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<div class="viewcode-block" id="QValueModule.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.QValueModule.html#torchrl.modules.QValueModule.forward">[docs]</a>    <span class="nd">@dispatch</span><span class="p">(</span><span class="n">auto_batch_size</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">action_values</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">action_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Action value key </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span><span class="si">}</span><span class="s2"> not found in </span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">action_mask</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">action_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Action mask key </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span><span class="si">}</span><span class="s2"> not found in </span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="n">action_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">action_mask</span><span class="p">,</span> <span class="n">action_values</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">action_values</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">min</span>
            <span class="p">)</span>

        <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_func_mapping</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">](</span><span class="n">action_values</span><span class="p">)</span>

        <span class="n">action_value_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_value_func_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_action_value</span>
        <span class="p">)</span>
        <span class="n">chosen_action_value</span> <span class="o">=</span> <span class="n">action_value_func</span><span class="p">(</span><span class="n">action_values</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">,</span> <span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">action_values</span><span class="p">,</span> <span class="n">chosen_action_value</span><span class="p">)))</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_one_hot</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="n">value</span> <span class="o">==</span> <span class="n">value</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_categorical</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_mult_one_hot</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">support</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_nums</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;var_nums must be provided to the constructor for multi one-hot action spaces.&quot;</span>
            <span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_nums</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_one_hot</span><span class="p">(</span>
                    <span class="n">_value</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">values</span>
            <span class="p">],</span>
            <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_binary</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">support</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_default_action_value</span><span class="p">(</span>
        <span class="n">values</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">action</span> <span class="o">*</span> <span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_categorical_action_value</span><span class="p">(</span>
        <span class="n">values</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">values</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span></div>
        <span class="c1"># if values.ndim == 1:</span>
        <span class="c1">#     return values[action].unsqueeze(-1)</span>
        <span class="c1"># batch_size = values.size(0)</span>
        <span class="c1"># return values[range(batch_size), action].unsqueeze(-1)</span>


<div class="viewcode-block" id="DistributionalQValueModule"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DistributionalQValueModule.html#torchrl.modules.DistributionalQValueModule">[docs]</a><span class="k">class</span> <span class="nc">DistributionalQValueModule</span><span class="p">(</span><span class="n">QValueModule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Distributional Q-Value hook for Q-value policies.</span>

<span class="sd">    This module processes a tensor containing action value logits into is argmax</span>
<span class="sd">    component (i.e. the resulting greedy action), following a given</span>
<span class="sd">    action space (one-hot, binary or categorical).</span>
<span class="sd">    It works with both tensordict and regular tensors.</span>

<span class="sd">    The input action value is expected to be the result of a log-softmax</span>
<span class="sd">    operation.</span>

<span class="sd">    For more details regarding Distributional DQN, refer to &quot;A Distributional Perspective on Reinforcement Learning&quot;,</span>
<span class="sd">    https://arxiv.org/pdf/1707.06887.pdf</span>

<span class="sd">    Args:</span>
<span class="sd">        action_space (str, optional): Action space. Must be one of</span>
<span class="sd">            ``&quot;one-hot&quot;``, ``&quot;mult-one-hot&quot;``, ``&quot;binary&quot;`` or ``&quot;categorical&quot;``.</span>
<span class="sd">            This argument is exclusive with ``spec``, since ``spec``</span>
<span class="sd">            conditions the action_space.</span>
<span class="sd">        support (torch.Tensor): support of the action values.</span>
<span class="sd">        action_value_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action value. Defaults to ``&quot;action_value&quot;``.</span>
<span class="sd">        action_mask_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action mask. Defaults to ``&quot;None&quot;`` (equivalent to no masking).</span>
<span class="sd">        out_keys (list of str or tuple of str, optional): The output keys</span>
<span class="sd">            representing the actions and action values.</span>
<span class="sd">            Defaults to ``[&quot;action&quot;, &quot;action_value&quot;]``.</span>
<span class="sd">        var_nums (int, optional): if ``action_space = &quot;mult-one-hot&quot;``,</span>
<span class="sd">            this value represents the cardinality of each</span>
<span class="sd">            action component.</span>
<span class="sd">        spec (TensorSpec, optional): if provided, the specs of the action (and/or</span>
<span class="sd">            other outputs). This is exclusive with ``action_space``, as the spec</span>
<span class="sd">            conditions the action space.</span>
<span class="sd">        safe (bool): if ``True``, the value of the output is checked against the</span>
<span class="sd">            input spec. Out-of-domain sampling can</span>
<span class="sd">            occur because of exploration policies or numerical under/overflow issues.</span>
<span class="sd">            If this value is out of bounds, it is projected back onto the</span>
<span class="sd">            desired space using the :obj:`TensorSpec.project`</span>
<span class="sd">            method. Default is ``False``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; action_space = &quot;categorical&quot;</span>
<span class="sd">        &gt;&gt;&gt; action_value_key = &quot;my_action_value&quot;</span>
<span class="sd">        &gt;&gt;&gt; support = torch.tensor([-1, 0.0, 1.0]) # the action value is between -1 and 1</span>
<span class="sd">        &gt;&gt;&gt; actor = DistributionalQValueModule(action_space, support=support, action_value_key=action_value_key)</span>
<span class="sd">        &gt;&gt;&gt; # This module works with both tensordict and regular tensors:</span>
<span class="sd">        &gt;&gt;&gt; value = torch.full((3, 4), -100)</span>
<span class="sd">        &gt;&gt;&gt; # the first bin (-1) of the first action is high: there&#39;s a high chance that it has a low value</span>
<span class="sd">        &gt;&gt;&gt; value[0, 0] = 0</span>
<span class="sd">        &gt;&gt;&gt; # the second bin (0) of the second action is high: there&#39;s a high chance that it has an intermediate value</span>
<span class="sd">        &gt;&gt;&gt; value[1, 1] = 0</span>
<span class="sd">        &gt;&gt;&gt; # the third bin (0) of the thid action is high: there&#39;s a high chance that it has an high value</span>
<span class="sd">        &gt;&gt;&gt; value[2, 2] = 0</span>
<span class="sd">        &gt;&gt;&gt; actor(my_action_value=value)</span>
<span class="sd">        (tensor(2), tensor([[   0, -100, -100, -100],</span>
<span class="sd">                [-100,    0, -100, -100],</span>
<span class="sd">                [-100, -100,    0, -100]]))</span>
<span class="sd">        &gt;&gt;&gt; actor(value)</span>
<span class="sd">        (tensor(2), tensor([[   0, -100, -100, -100],</span>
<span class="sd">                [-100,    0, -100, -100],</span>
<span class="sd">                [-100, -100,    0, -100]]))</span>
<span class="sd">        &gt;&gt;&gt; actor(TensorDict({action_value_key: value}, []))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                my_action_value: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.int64, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">support</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">action_value_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_mask_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">var_nums</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">spec</span><span class="p">:</span> <span class="n">TensorSpec</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">safe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">action_value_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">action_value_key</span> <span class="o">=</span> <span class="s2">&quot;action_value&quot;</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">,</span> <span class="n">action_value_key</span><span class="p">]</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
            <span class="n">action_value_key</span><span class="o">=</span><span class="n">action_value_key</span><span class="p">,</span>
            <span class="n">action_mask_key</span><span class="o">=</span><span class="n">action_mask_key</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">var_nums</span><span class="o">=</span><span class="n">var_nums</span><span class="p">,</span>
            <span class="n">spec</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span>
            <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;support&quot;</span><span class="p">,</span> <span class="n">support</span><span class="p">)</span>

<div class="viewcode-block" id="DistributionalQValueModule.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DistributionalQValueModule.html#torchrl.modules.DistributionalQValueModule.forward">[docs]</a>    <span class="nd">@dispatch</span><span class="p">(</span><span class="n">auto_batch_size</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">action_values</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">action_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Action value key </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span><span class="si">}</span><span class="s2"> not found in </span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">action_mask</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">action_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Action mask key </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span><span class="si">}</span><span class="s2"> not found in </span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="n">action_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">action_mask</span><span class="p">,</span> <span class="n">action_values</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">action_values</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">min</span>
            <span class="p">)</span>

        <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_func_mapping</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">](</span><span class="n">action_values</span><span class="p">)</span>

        <span class="n">tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="nb">dict</span><span class="p">(</span>
                <span class="nb">zip</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">,</span>
                    <span class="p">(</span>
                        <span class="n">action</span><span class="p">,</span>
                        <span class="n">action_values</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div>

    <span class="k">def</span> <span class="nf">_support_expected</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">log_softmax_values</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">support</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">support</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">support</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">support</span>
        <span class="n">support</span> <span class="o">=</span> <span class="n">support</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">log_softmax_values</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">log_softmax_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span> <span class="n">support</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Support length and number of atoms in module output should match, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;got self.support.shape=</span><span class="si">{</span><span class="n">support</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and module(...).shape=</span><span class="si">{</span><span class="n">log_softmax_values</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">log_softmax_values</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;input to QValueHook must be log-softmax values (which are expected to be non-positive numbers). &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;got a maximum value of </span><span class="si">{</span><span class="n">log_softmax_values</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">log_softmax_values</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">*</span> <span class="n">support</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_one_hot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">support</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">support</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">support</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">support</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;got value of type </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">support</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;got support of type </span><span class="si">{</span><span class="n">support</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_support_expected</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="n">value</span> <span class="o">==</span> <span class="n">value</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">_mult_one_hot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">support</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">support</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">support</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">support</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_nums</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_one_hot</span><span class="p">(</span><span class="n">_value</span><span class="p">,</span> <span class="n">_support</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">_value</span><span class="p">,</span> <span class="n">_support</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">support</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_categorical</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_support_expected</span><span class="p">(</span>
            <span class="n">value</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_binary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;&#39;binary&#39; is currently not supported for DistributionalQValueModule.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="QValueHook"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.QValueHook.html#torchrl.modules.QValueHook">[docs]</a><span class="k">class</span> <span class="nc">QValueHook</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Q-Value hook for Q-value policies.</span>

<span class="sd">    Given the output of a regular nn.Module, representing the values of the</span>
<span class="sd">    different discrete actions available,</span>
<span class="sd">    a QValueHook will transform these values into their argmax component (i.e.</span>
<span class="sd">    the resulting greedy action).</span>

<span class="sd">    Args:</span>
<span class="sd">        action_space (str): Action space. Must be one of</span>
<span class="sd">            ``&quot;one-hot&quot;``, ``&quot;mult-one-hot&quot;``, ``&quot;binary&quot;`` or ``&quot;categorical&quot;``.</span>
<span class="sd">        var_nums (int, optional): if ``action_space = &quot;mult-one-hot&quot;``,</span>
<span class="sd">            this value represents the cardinality of each</span>
<span class="sd">            action component.</span>
<span class="sd">        action_value_key (str or tuple of str, optional): to be used when hooked on</span>
<span class="sd">            a TensorDictModule. The input key representing the action value. Defaults</span>
<span class="sd">            to ``&quot;action_value&quot;``.</span>
<span class="sd">        action_mask_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action mask. Defaults to ``&quot;None&quot;`` (equivalent to no masking).</span>
<span class="sd">        out_keys (list of str or tuple of str, optional): to be used when hooked on</span>
<span class="sd">            a TensorDictModule. The output keys representing the actions, action values</span>
<span class="sd">            and chosen action value. Defaults to ``[&quot;action&quot;, &quot;action_value&quot;, &quot;chosen_action_value&quot;]``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import OneHotDiscreteTensorSpec</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.tensordict_module.actors import QValueHook, Actor</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;observation&#39;: torch.randn(5, 4)}, [5])</span>
<span class="sd">        &gt;&gt;&gt; module = nn.Linear(4, 4)</span>
<span class="sd">        &gt;&gt;&gt; hook = QValueHook(&quot;one_hot&quot;)</span>
<span class="sd">        &gt;&gt;&gt; module.register_forward_hook(hook)</span>
<span class="sd">        &gt;&gt;&gt; action_spec = OneHotDiscreteTensorSpec(4)</span>
<span class="sd">        &gt;&gt;&gt; qvalue_actor = Actor(module=module, spec=action_spec, out_keys=[&quot;action&quot;, &quot;action_value&quot;])</span>
<span class="sd">        &gt;&gt;&gt; td = qvalue_actor(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                action_value: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([5]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">var_nums</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_value_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_mask_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Using specs in action_space will be deprecated in v0.4.0,&quot;</span>
                <span class="s2">&quot; please use the &#39;spec&#39; argument if you want to provide an action spec&quot;</span><span class="p">,</span>
                <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">action_space</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_process_action_space_spec</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">qvalue_model</span> <span class="o">=</span> <span class="n">QValueModule</span><span class="p">(</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
            <span class="n">var_nums</span><span class="o">=</span><span class="n">var_nums</span><span class="p">,</span>
            <span class="n">action_value_key</span><span class="o">=</span><span class="n">action_value_key</span><span class="p">,</span>
            <span class="n">action_mask_key</span><span class="o">=</span><span class="n">action_mask_key</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">action_value_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qvalue_model</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_value_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">action_value_key</span> <span class="o">=</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">action_value_key</span><span class="p">)</span>
        <span class="c1"># uses &quot;dispatch&quot; to get and return tensors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span> <span class="o">=</span> <span class="n">action_value_key</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">values</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span><span class="p">:</span> <span class="n">values</span><span class="p">}</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">qvalue_model</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="DistributionalQValueHook"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.DistributionalQValueHook.html#torchrl.modules.DistributionalQValueHook">[docs]</a><span class="k">class</span> <span class="nc">DistributionalQValueHook</span><span class="p">(</span><span class="n">QValueHook</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Distributional Q-Value hook for Q-value policies.</span>

<span class="sd">    Given the output of a mapping operator, representing the log-probability of the</span>
<span class="sd">    different action value bin available,</span>
<span class="sd">    a DistributionalQValueHook will transform these values into their argmax</span>
<span class="sd">    component using the provided support.</span>

<span class="sd">    For more details regarding Distributional DQN, refer to &quot;A Distributional Perspective on Reinforcement Learning&quot;,</span>
<span class="sd">    https://arxiv.org/pdf/1707.06887.pdf</span>

<span class="sd">    Args:</span>
<span class="sd">        action_space (str): Action space. Must be one of</span>
<span class="sd">            ``&quot;one-hot&quot;``, ``&quot;mult-one-hot&quot;``, ``&quot;binary&quot;`` or ``&quot;categorical&quot;``.</span>
<span class="sd">        action_value_key (str or tuple of str, optional): to be used when hooked on</span>
<span class="sd">            a TensorDictModule. The input key representing the action value. Defaults</span>
<span class="sd">            to ``&quot;action_value&quot;``.</span>
<span class="sd">        action_mask_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action mask. Defaults to ``&quot;None&quot;`` (equivalent to no masking).</span>
<span class="sd">        support (torch.Tensor): support of the action values.</span>
<span class="sd">        var_nums (int, optional): if ``action_space = &quot;mult-one-hot&quot;``, this</span>
<span class="sd">            value represents the cardinality of each</span>
<span class="sd">            action component.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import OneHotDiscreteTensorSpec</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.tensordict_module.actors import DistributionalQValueHook, Actor</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;observation&#39;: torch.randn(5, 4)}, [5])</span>
<span class="sd">        &gt;&gt;&gt; nbins = 3</span>
<span class="sd">        &gt;&gt;&gt; class CustomDistributionalQval(nn.Module):</span>
<span class="sd">        ...     def __init__(self):</span>
<span class="sd">        ...         super().__init__()</span>
<span class="sd">        ...         self.linear = nn.Linear(4, nbins*4)</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def forward(self, x):</span>
<span class="sd">        ...         return self.linear(x).view(-1, nbins, 4).log_softmax(-2)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; module = CustomDistributionalQval()</span>
<span class="sd">        &gt;&gt;&gt; params = TensorDict.from_module(module)</span>
<span class="sd">        &gt;&gt;&gt; action_spec = OneHotDiscreteTensorSpec(4)</span>
<span class="sd">        &gt;&gt;&gt; hook = DistributionalQValueHook(&quot;one_hot&quot;, support = torch.arange(nbins))</span>
<span class="sd">        &gt;&gt;&gt; module.register_forward_hook(hook)</span>
<span class="sd">        &gt;&gt;&gt; qvalue_actor = Actor(module=module, spec=action_spec, out_keys=[&quot;action&quot;, &quot;action_value&quot;])</span>
<span class="sd">        &gt;&gt;&gt; with params.to_module(module):</span>
<span class="sd">        ...     qvalue_actor(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(torch.Size([5, 4]), dtype=torch.int64),</span>
<span class="sd">                action_value: Tensor(torch.Size([5, 3, 4]), dtype=torch.float32),</span>
<span class="sd">                observation: Tensor(torch.Size([5, 4]), dtype=torch.float32)},</span>
<span class="sd">            batch_size=torch.Size([5]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">support</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">var_nums</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_value_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_mask_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Using specs in action_space will be deprecated in v0.4.0,&quot;</span>
                <span class="s2">&quot; please use the &#39;spec&#39; argument if you want to provide an action spec&quot;</span><span class="p">,</span>
                <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">action_space</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_process_action_space_spec</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qvalue_model</span> <span class="o">=</span> <span class="n">DistributionalQValueModule</span><span class="p">(</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
            <span class="n">var_nums</span><span class="o">=</span><span class="n">var_nums</span><span class="p">,</span>
            <span class="n">support</span><span class="o">=</span><span class="n">support</span><span class="p">,</span>
            <span class="n">action_value_key</span><span class="o">=</span><span class="n">action_value_key</span><span class="p">,</span>
            <span class="n">action_mask_key</span><span class="o">=</span><span class="n">action_mask_key</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">action_value_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qvalue_model</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_value_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">action_value_key</span> <span class="o">=</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">action_value_key</span><span class="p">)</span>
        <span class="c1"># uses &quot;dispatch&quot; to get and return tensors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span> <span class="o">=</span> <span class="n">action_value_key</span></div>


<div class="viewcode-block" id="QValueActor"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.QValueActor">[docs]</a><span class="k">class</span> <span class="nc">QValueActor</span><span class="p">(</span><span class="n">SafeSequential</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Q-Value actor class.</span>

<span class="sd">    This class appends a :class:`~.QValueModule` after the input module</span>
<span class="sd">    such that the action values are used to select an action.</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module): a :class:`torch.nn.Module` used to map the input to</span>
<span class="sd">            the output parameter space. If the class provided is not compatible</span>
<span class="sd">            with :class:`tensordict.nn.TensorDictModuleBase`, it will be</span>
<span class="sd">            wrapped in a :class:`tensordict.nn.TensorDictModule` with</span>
<span class="sd">            ``in_keys`` indicated by the following keyword argument.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        in_keys (iterable of str, optional): If the class provided is not</span>
<span class="sd">            compatible with :class:`tensordict.nn.TensorDictModuleBase`, this</span>
<span class="sd">            list of keys indicates what observations need to be passed to the</span>
<span class="sd">            wrapped module to get the action values.</span>
<span class="sd">            Defaults to ``[&quot;observation&quot;]``.</span>
<span class="sd">        spec (TensorSpec, optional): Keyword-only argument.</span>
<span class="sd">            Specs of the output tensor. If the module</span>
<span class="sd">            outputs multiple output tensors,</span>
<span class="sd">            spec characterize the space of the first output tensor.</span>
<span class="sd">        safe (bool): Keyword-only argument.</span>
<span class="sd">            If ``True``, the value of the output is checked against the</span>
<span class="sd">            input spec. Out-of-domain sampling can</span>
<span class="sd">            occur because of exploration policies or numerical under/overflow</span>
<span class="sd">            issues. If this value is out of bounds, it is projected back onto the</span>
<span class="sd">            desired space using the :obj:`TensorSpec.project`</span>
<span class="sd">            method. Default is ``False``.</span>
<span class="sd">        action_space (str, optional): Action space. Must be one of</span>
<span class="sd">            ``&quot;one-hot&quot;``, ``&quot;mult-one-hot&quot;``, ``&quot;binary&quot;`` or ``&quot;categorical&quot;``.</span>
<span class="sd">            This argument is exclusive with ``spec``, since ``spec``</span>
<span class="sd">            conditions the action_space.</span>
<span class="sd">        action_value_key (str or tuple of str, optional): if the input module</span>
<span class="sd">            is a :class:`tensordict.nn.TensorDictModuleBase` instance, it must</span>
<span class="sd">            match one of its output keys. Otherwise, this string represents</span>
<span class="sd">            the name of the action-value entry in the output tensordict.</span>
<span class="sd">        action_mask_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action mask. Defaults to ``&quot;None&quot;`` (equivalent to no masking).</span>

<span class="sd">    .. note::</span>
<span class="sd">        ``out_keys`` cannot be passed. If the module is a :class:`tensordict.nn.TensorDictModule`</span>
<span class="sd">        instance, the out_keys will be updated accordingly. For regular</span>
<span class="sd">        :class:`torch.nn.Module` instance, the triplet ``[&quot;action&quot;, action_value_key, &quot;chosen_action_value&quot;]``</span>
<span class="sd">        will be used.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import OneHotDiscreteTensorSpec</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.tensordict_module.actors import QValueActor</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;observation&#39;: torch.randn(5, 4)}, [5])</span>
<span class="sd">        &gt;&gt;&gt; # with a regular nn.Module</span>
<span class="sd">        &gt;&gt;&gt; module = nn.Linear(4, 4)</span>
<span class="sd">        &gt;&gt;&gt; action_spec = OneHotDiscreteTensorSpec(4)</span>
<span class="sd">        &gt;&gt;&gt; qvalue_actor = QValueActor(module=module, spec=action_spec)</span>
<span class="sd">        &gt;&gt;&gt; td = qvalue_actor(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                action_value: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                chosen_action_value: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([5]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; # with a TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;obs&#39;: torch.randn(5, 4)}, [5])</span>
<span class="sd">        &gt;&gt;&gt; module = TensorDictModule(lambda x: x, in_keys=[&quot;obs&quot;], out_keys=[&quot;action_value&quot;])</span>
<span class="sd">        &gt;&gt;&gt; action_spec = OneHotDiscreteTensorSpec(4)</span>
<span class="sd">        &gt;&gt;&gt; qvalue_actor = QValueActor(module=module, spec=action_spec)</span>
<span class="sd">        &gt;&gt;&gt; td = qvalue_actor(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                action_value: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                chosen_action_value: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                obs: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([5]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">spec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">safe</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_value_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">action_mask_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Using specs in action_space will be deprecated v0.4.0,&quot;</span>
                <span class="s2">&quot; please use the &#39;spec&#39; argument if you want to provide an action spec&quot;</span><span class="p">,</span>
                <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">action_space</span><span class="p">,</span> <span class="n">spec</span> <span class="o">=</span> <span class="n">_process_action_space_spec</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">spec</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span> <span class="o">=</span> <span class="n">action_value_key</span>
        <span class="k">if</span> <span class="n">action_value_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">action_value_key</span> <span class="o">=</span> <span class="s2">&quot;action_value&quot;</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;action&quot;</span><span class="p">,</span>
            <span class="n">action_value_key</span><span class="p">,</span>
            <span class="s2">&quot;chosen_action_value&quot;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">TensorDictModuleBase</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">action_value_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">out_keys</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The key &#39;</span><span class="si">{</span><span class="n">action_value_key</span><span class="si">}</span><span class="s2">&#39; is not part of the module out-keys.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">]</span>
            <span class="n">module</span> <span class="o">=</span> <span class="n">TensorDictModule</span><span class="p">(</span>
                <span class="n">module</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="n">action_value_key</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">CompositeSpec</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">CompositeSpec</span><span class="p">):</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">if</span> <span class="s2">&quot;action&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">spec</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">CompositeSpec</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">spec</span><span class="p">[</span><span class="n">action_value_key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">spec</span><span class="p">[</span><span class="s2">&quot;chosen_action_value&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">qvalue</span> <span class="o">=</span> <span class="n">QValueModule</span><span class="p">(</span>
            <span class="n">action_value_key</span><span class="o">=</span><span class="n">action_value_key</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">spec</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span>
            <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">,</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
            <span class="n">action_mask_key</span><span class="o">=</span><span class="n">action_mask_key</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">qvalue</span><span class="p">)</span></div>


<div class="viewcode-block" id="DistributionalQValueActor"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DistributionalQValueActor.html#torchrl.modules.DistributionalQValueActor">[docs]</a><span class="k">class</span> <span class="nc">DistributionalQValueActor</span><span class="p">(</span><span class="n">QValueActor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Distributional DQN actor class.</span>

<span class="sd">    This class appends a :class:`~.QValueModule` after the input module</span>
<span class="sd">    such that the action values are used to select an action.</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module): a :class:`torch.nn.Module` used to map the input to</span>
<span class="sd">            the output parameter space.</span>
<span class="sd">            If the module isn&#39;t of type :class:`torchrl.modules.DistributionalDQNnet`,</span>
<span class="sd">            :class:`~.DistributionalQValueActor` will ensure that a log-softmax</span>
<span class="sd">            operation is applied to the action value tensor along dimension ``-2``.</span>
<span class="sd">            This can be deactivated by turning off the ``make_log_softmax``</span>
<span class="sd">            keyword argument.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        in_keys (iterable of str, optional): keys to be read from input</span>
<span class="sd">            tensordict and passed to the module. If it</span>
<span class="sd">            contains more than one element, the values will be passed in the</span>
<span class="sd">            order given by the in_keys iterable.</span>
<span class="sd">            Defaults to ``[&quot;observation&quot;]``.</span>
<span class="sd">        spec (TensorSpec, optional): Keyword-only argument.</span>
<span class="sd">            Specs of the output tensor. If the module</span>
<span class="sd">            outputs multiple output tensors,</span>
<span class="sd">            spec characterize the space of the first output tensor.</span>
<span class="sd">        safe (bool): Keyword-only argument.</span>
<span class="sd">            If ``True``, the value of the output is checked against the</span>
<span class="sd">            input spec. Out-of-domain sampling can</span>
<span class="sd">            occur because of exploration policies or numerical under/overflow</span>
<span class="sd">            issues. If this value is out of bounds, it is projected back onto the</span>
<span class="sd">            desired space using the :obj:`TensorSpec.project`</span>
<span class="sd">            method. Default is ``False``.</span>
<span class="sd">        var_nums (int, optional): if ``action_space = &quot;mult-one-hot&quot;``,</span>
<span class="sd">            this value represents the cardinality of each</span>
<span class="sd">            action component.</span>
<span class="sd">        support (torch.Tensor): support of the action values.</span>
<span class="sd">        action_space (str, optional): Action space. Must be one of</span>
<span class="sd">            ``&quot;one-hot&quot;``, ``&quot;mult-one-hot&quot;``, ``&quot;binary&quot;`` or ``&quot;categorical&quot;``.</span>
<span class="sd">            This argument is exclusive with ``spec``, since ``spec``</span>
<span class="sd">            conditions the action_space.</span>
<span class="sd">        make_log_softmax (bool, optional): if ``True`` and if the module is not</span>
<span class="sd">            of type :class:`torchrl.modules.DistributionalDQNnet`, a log-softmax</span>
<span class="sd">            operation will be applied along dimension -2 of the action value tensor.</span>
<span class="sd">        action_value_key (str or tuple of str, optional): if the input module</span>
<span class="sd">            is a :class:`tensordict.nn.TensorDictModuleBase` instance, it must</span>
<span class="sd">            match one of its output keys. Otherwise, this string represents</span>
<span class="sd">            the name of the action-value entry in the output tensordict.</span>
<span class="sd">        action_mask_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action mask. Defaults to ``&quot;None&quot;`` (equivalent to no masking).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule, TensorDictSequential</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import OneHotDiscreteTensorSpec</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import DistributionalQValueActor, MLP</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;observation&#39;: torch.randn(5, 4)}, [5])</span>
<span class="sd">        &gt;&gt;&gt; nbins = 3</span>
<span class="sd">        &gt;&gt;&gt; module = MLP(out_features=(nbins, 4), depth=2)</span>
<span class="sd">        &gt;&gt;&gt; # let us make sure that the output is a log-softmax</span>
<span class="sd">        &gt;&gt;&gt; module = TensorDictSequential(</span>
<span class="sd">        ...     TensorDictModule(module, [&quot;observation&quot;], [&quot;action_value&quot;]),</span>
<span class="sd">        ...     TensorDictModule(lambda x: x.log_softmax(-2), [&quot;action_value&quot;], [&quot;action_value&quot;]),</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; action_spec = OneHotDiscreteTensorSpec(4)</span>
<span class="sd">        &gt;&gt;&gt; qvalue_actor = DistributionalQValueActor(</span>
<span class="sd">        ...     module=module,</span>
<span class="sd">        ...     spec=action_spec,</span>
<span class="sd">        ...     support=torch.arange(nbins))</span>
<span class="sd">        &gt;&gt;&gt; td = qvalue_actor(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                action_value: Tensor(shape=torch.Size([5, 3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([5]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">,</span>
        <span class="n">support</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">spec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">safe</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">var_nums</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_value_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;action_value&quot;</span><span class="p">,</span>
        <span class="n">action_mask_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">make_log_softmax</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Using specs in action_space will be deprecated in v0.4.0,&quot;</span>
                <span class="s2">&quot; please use the &#39;spec&#39; argument if you want to provide an action spec&quot;</span><span class="p">,</span>
                <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">action_space</span><span class="p">,</span> <span class="n">spec</span> <span class="o">=</span> <span class="n">_process_action_space_spec</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">spec</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span> <span class="o">=</span> <span class="n">action_value_key</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;action&quot;</span><span class="p">,</span>
            <span class="n">action_value_key</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">TensorDictModuleBase</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">action_value_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">out_keys</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The key &#39;</span><span class="si">{</span><span class="n">action_value_key</span><span class="si">}</span><span class="s2">&#39; is not part of the module out-keys.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">]</span>
            <span class="n">module</span> <span class="o">=</span> <span class="n">TensorDictModule</span><span class="p">(</span>
                <span class="n">module</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="n">action_value_key</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">CompositeSpec</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">CompositeSpec</span><span class="p">):</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">if</span> <span class="s2">&quot;action&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">spec</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">CompositeSpec</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">spec</span><span class="p">[</span><span class="n">action_value_key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">qvalue</span> <span class="o">=</span> <span class="n">DistributionalQValueModule</span><span class="p">(</span>
            <span class="n">action_value_key</span><span class="o">=</span><span class="n">action_value_key</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">spec</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span>
            <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">,</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
            <span class="n">action_mask_key</span><span class="o">=</span><span class="n">action_mask_key</span><span class="p">,</span>
            <span class="n">support</span><span class="o">=</span><span class="n">support</span><span class="p">,</span>
            <span class="n">var_nums</span><span class="o">=</span><span class="n">var_nums</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">make_log_softmax</span> <span class="o">=</span> <span class="n">make_log_softmax</span>
        <span class="k">if</span> <span class="n">make_log_softmax</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">DistributionalDQNnet</span><span class="p">):</span>
            <span class="n">log_softmax_module</span> <span class="o">=</span> <span class="n">DistributionalDQNnet</span><span class="p">(</span>
                <span class="n">in_keys</span><span class="o">=</span><span class="n">qvalue</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">qvalue</span><span class="o">.</span><span class="n">in_keys</span>
            <span class="p">)</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">QValueActor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">log_softmax_module</span><span class="p">,</span> <span class="n">qvalue</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">QValueActor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">qvalue</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;support&quot;</span><span class="p">,</span> <span class="n">support</span><span class="p">)</span></div>


<div class="viewcode-block" id="ActorValueOperator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.html#torchrl.modules.ActorValueOperator">[docs]</a><span class="k">class</span> <span class="nc">ActorValueOperator</span><span class="p">(</span><span class="n">SafeSequential</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Actor-value operator.</span>

<span class="sd">    This class wraps together an actor and a value model that share a common</span>
<span class="sd">    observation embedding network:</span>

<span class="sd">    .. aafig::</span>
<span class="sd">        :aspect: 60</span>
<span class="sd">        :scale: 120</span>
<span class="sd">        :proportional:</span>
<span class="sd">        :textual:</span>

<span class="sd">               +---------------+</span>
<span class="sd">               |Observation (s)|</span>
<span class="sd">               +---------------+</span>
<span class="sd">                        |</span>
<span class="sd">                       &quot;common&quot;</span>
<span class="sd">                        |</span>
<span class="sd">                        v</span>
<span class="sd">                 +------------+</span>
<span class="sd">                 |Hidden state|</span>
<span class="sd">                 +------------+</span>
<span class="sd">                   |         |</span>
<span class="sd">                  actor     critic</span>
<span class="sd">                   |         |</span>
<span class="sd">                   v         v</span>
<span class="sd">        +-------------+ +------------+</span>
<span class="sd">        |Action (a(s))| |Value (V(s))|</span>
<span class="sd">        +-------------+ +------------+</span>

<span class="sd">    .. note::</span>
<span class="sd">      For a similar class that returns an action and a Quality value :math:`Q(s, a)`</span>
<span class="sd">      see :class:`~.ActorCriticOperator`. For a version without common embeddig</span>
<span class="sd">      refet to :class:`~.ActorCriticWrapper`.</span>

<span class="sd">    To facilitate the workflow, this  class comes with a get_policy_operator() and get_value_operator() methods, which</span>
<span class="sd">    will both return a standalone TDModule with the dedicated functionality.</span>

<span class="sd">    Args:</span>
<span class="sd">        common_operator (TensorDictModule): a common operator that reads</span>
<span class="sd">            observations and produces a hidden variable</span>
<span class="sd">        policy_operator (TensorDictModule): a policy operator that reads the</span>
<span class="sd">            hidden variable and returns an action</span>
<span class="sd">        value_operator (TensorDictModule): a value operator, that reads the</span>
<span class="sd">            hidden variable and returns a value</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import ProbabilisticActor, SafeModule</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import ValueOperator, TanhNormal, ActorValueOperator, NormalParamWrapper</span>
<span class="sd">        &gt;&gt;&gt; module_hidden = torch.nn.Linear(4, 4)</span>
<span class="sd">        &gt;&gt;&gt; td_module_hidden = SafeModule(</span>
<span class="sd">        ...    module=module_hidden,</span>
<span class="sd">        ...    in_keys=[&quot;observation&quot;],</span>
<span class="sd">        ...    out_keys=[&quot;hidden&quot;],</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; module_action = TensorDictModule(</span>
<span class="sd">        ...     NormalParamWrapper(torch.nn.Linear(4, 8)),</span>
<span class="sd">        ...     in_keys=[&quot;hidden&quot;],</span>
<span class="sd">        ...     out_keys=[&quot;loc&quot;, &quot;scale&quot;],</span>
<span class="sd">        ...     )</span>
<span class="sd">        &gt;&gt;&gt; td_module_action = ProbabilisticActor(</span>
<span class="sd">        ...    module=module_action,</span>
<span class="sd">        ...    in_keys=[&quot;loc&quot;, &quot;scale&quot;],</span>
<span class="sd">        ...    out_keys=[&quot;action&quot;],</span>
<span class="sd">        ...    distribution_class=TanhNormal,</span>
<span class="sd">        ...    return_log_prob=True,</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; module_value = torch.nn.Linear(4, 1)</span>
<span class="sd">        &gt;&gt;&gt; td_module_value = ValueOperator(</span>
<span class="sd">        ...    module=module_value,</span>
<span class="sd">        ...    in_keys=[&quot;hidden&quot;],</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; td_module = ActorValueOperator(td_module_hidden, td_module_action, td_module_value)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(3, 4)}, [3,])</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module.get_policy_operator()(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)  # no value</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module.get_value_operator()(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)  # no action</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">common_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="n">policy_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="n">value_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">common_operator</span><span class="p">,</span>
            <span class="n">policy_operator</span><span class="p">,</span>
            <span class="n">value_operator</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="ActorValueOperator.get_policy_operator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.html#torchrl.modules.ActorValueOperator.get_policy_operator">[docs]</a>    <span class="k">def</span> <span class="nf">get_policy_operator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a standalone policy operator that maps an observation to an action.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">SafeProbabilisticTensorDictSequential</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">SafeProbabilisticTensorDictSequential</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">module</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">SafeSequential</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></div>

<div class="viewcode-block" id="ActorValueOperator.get_value_operator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.html#torchrl.modules.ActorValueOperator.get_value_operator">[docs]</a>    <span class="k">def</span> <span class="nf">get_value_operator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a standalone value network operator that maps an observation to a value estimate.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">SafeSequential</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span></div>

<div class="viewcode-block" id="ActorValueOperator.get_policy_head"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.html#torchrl.modules.ActorValueOperator.get_policy_head">[docs]</a>    <span class="k">def</span> <span class="nf">get_policy_head</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the policy head.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span></div>

<div class="viewcode-block" id="ActorValueOperator.get_value_head"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.html#torchrl.modules.ActorValueOperator.get_value_head">[docs]</a>    <span class="k">def</span> <span class="nf">get_value_head</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the value head.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span></div></div>


<div class="viewcode-block" id="ActorCriticOperator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.html#torchrl.modules.ActorCriticOperator">[docs]</a><span class="k">class</span> <span class="nc">ActorCriticOperator</span><span class="p">(</span><span class="n">ActorValueOperator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Actor-critic operator.</span>

<span class="sd">    This class wraps together an actor and a value model that share a common</span>
<span class="sd">    observation embedding network:</span>

<span class="sd">    .. aafig::</span>
<span class="sd">        :aspect: 60</span>
<span class="sd">        :scale: 120</span>
<span class="sd">        :proportional:</span>
<span class="sd">        :textual:</span>

<span class="sd">                 +---------------+</span>
<span class="sd">                 |Observation (s)|</span>
<span class="sd">                 +---------------+</span>
<span class="sd">                         |</span>
<span class="sd">                         v</span>
<span class="sd">                        &quot;common&quot;</span>
<span class="sd">                         |</span>
<span class="sd">                         v</span>
<span class="sd">                  +------------+</span>
<span class="sd">                  |Hidden state|</span>
<span class="sd">                  +------------+</span>
<span class="sd">                    |        |</span>
<span class="sd">                    v        v</span>
<span class="sd">                   actor --&gt; critic</span>
<span class="sd">                    |        |</span>
<span class="sd">                    v        v</span>
<span class="sd">            +-------------+ +----------------+</span>
<span class="sd">            |Action (a(s))| |Quality (Q(s,a))|</span>
<span class="sd">            +-------------+ +----------------+</span>

<span class="sd">    .. note::</span>
<span class="sd">      For a similar class that returns an action and a state-value :math:`V(s)`</span>
<span class="sd">      see :class:`~.ActorValueOperator`.</span>


<span class="sd">    To facilitate the workflow, this  class comes with a get_policy_operator() method, which</span>
<span class="sd">    will both return a standalone TDModule with the dedicated functionality. The get_critic_operator will return the</span>
<span class="sd">    parent object, as the value is computed based on the policy output.</span>

<span class="sd">    Args:</span>
<span class="sd">        common_operator (TensorDictModule): a common operator that reads</span>
<span class="sd">            observations and produces a hidden variable</span>
<span class="sd">        policy_operator (TensorDictModule): a policy operator that reads the</span>
<span class="sd">            hidden variable and returns an action</span>
<span class="sd">        value_operator (TensorDictModule): a value operator, that reads the</span>
<span class="sd">            hidden variable and returns a value</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import ProbabilisticActor</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import  ValueOperator, TanhNormal, ActorCriticOperator, NormalParamWrapper, MLP</span>
<span class="sd">        &gt;&gt;&gt; module_hidden = torch.nn.Linear(4, 4)</span>
<span class="sd">        &gt;&gt;&gt; td_module_hidden = SafeModule(</span>
<span class="sd">        ...    module=module_hidden,</span>
<span class="sd">        ...    in_keys=[&quot;observation&quot;],</span>
<span class="sd">        ...    out_keys=[&quot;hidden&quot;],</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; module_action = NormalParamWrapper(torch.nn.Linear(4, 8))</span>
<span class="sd">        &gt;&gt;&gt; module_action = TensorDictModule(module_action, in_keys=[&quot;hidden&quot;], out_keys=[&quot;loc&quot;, &quot;scale&quot;])</span>
<span class="sd">        &gt;&gt;&gt; td_module_action = ProbabilisticActor(</span>
<span class="sd">        ...    module=module_action,</span>
<span class="sd">        ...    in_keys=[&quot;loc&quot;, &quot;scale&quot;],</span>
<span class="sd">        ...    out_keys=[&quot;action&quot;],</span>
<span class="sd">        ...    distribution_class=TanhNormal,</span>
<span class="sd">        ...    return_log_prob=True,</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; module_value = MLP(in_features=8, out_features=1, num_cells=[])</span>
<span class="sd">        &gt;&gt;&gt; td_module_value = ValueOperator(</span>
<span class="sd">        ...    module=module_value,</span>
<span class="sd">        ...    in_keys=[&quot;hidden&quot;, &quot;action&quot;],</span>
<span class="sd">        ...    out_keys=[&quot;state_action_value&quot;],</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; td_module = ActorCriticOperator(td_module_hidden, td_module_action, td_module_value)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(3, 4)}, [3,])</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_action_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module.get_policy_operator()(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)  # no value</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module.get_critic_operator()(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)  # no action</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_action_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">common_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="n">policy_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="n">value_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">common_operator</span><span class="p">,</span>
            <span class="n">policy_operator</span><span class="p">,</span>
            <span class="n">value_operator</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;state_value&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Value out_key is state_value, which may lead to errors in downstream usages&quot;</span>
                <span class="s2">&quot;of that module. Consider setting `&#39;state_action_value&#39;` instead.&quot;</span>
                <span class="s2">&quot;Make also sure that `&#39;action&#39;` is amongst the input keys of the value network.&quot;</span>
                <span class="s2">&quot;If you are confident that action should not be used to compute the value, please&quot;</span>
                <span class="s2">&quot;user `ActorValueOperator` instead.&quot;</span>
            <span class="p">)</span>

<div class="viewcode-block" id="ActorCriticOperator.get_critic_operator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.html#torchrl.modules.ActorCriticOperator.get_critic_operator">[docs]</a>    <span class="k">def</span> <span class="nf">get_critic_operator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictModuleWrapper</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a standalone critic network operator that maps a state-action pair to a critic estimate.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="ActorCriticOperator.get_value_operator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.html#torchrl.modules.ActorCriticOperator.get_value_operator">[docs]</a>    <span class="k">def</span> <span class="nf">get_value_operator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictModuleWrapper</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;value_operator is the term used for operators that associate a value with a &quot;</span>
            <span class="s2">&quot;state/observation. This class computes the value of a state-action pair: to get the &quot;</span>
            <span class="s2">&quot;network computing this value, please call td_sequence.get_critic_operator()&quot;</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ActorCriticOperator.get_policy_head"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.html#torchrl.modules.ActorCriticOperator.get_policy_head">[docs]</a>    <span class="k">def</span> <span class="nf">get_policy_head</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the policy head.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span></div>

<div class="viewcode-block" id="ActorCriticOperator.get_value_head"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.html#torchrl.modules.ActorCriticOperator.get_value_head">[docs]</a>    <span class="k">def</span> <span class="nf">get_value_head</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the value head.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span></div></div>


<div class="viewcode-block" id="ActorCriticWrapper"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper.html#torchrl.modules.ActorCriticWrapper">[docs]</a><span class="k">class</span> <span class="nc">ActorCriticWrapper</span><span class="p">(</span><span class="n">SafeSequential</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Actor-value operator without common module.</span>

<span class="sd">    This class wraps together an actor and a value model that do not share a common observation embedding network:</span>

<span class="sd">    .. aafig::</span>
<span class="sd">        :aspect: 60</span>
<span class="sd">        :scale: 120</span>
<span class="sd">        :proportional:</span>
<span class="sd">        :textual:</span>

<span class="sd">                 +---------------+</span>
<span class="sd">                 |Observation (s)|</span>
<span class="sd">                 +---------------+</span>
<span class="sd">                    |    |    |</span>
<span class="sd">                    v    |    v</span>
<span class="sd">                   actor |    critic</span>
<span class="sd">                    |    |    |</span>
<span class="sd">                    v    |    v</span>
<span class="sd">        +-------------+  |  +------------+</span>
<span class="sd">        |Action (a(s))|  |  |Value (V(s))|</span>
<span class="sd">        +-------------+  |  +------------+</span>


<span class="sd">    To facilitate the workflow, this  class comes with a get_policy_operator() and get_value_operator() methods, which</span>
<span class="sd">    will both return a standalone TDModule with the dedicated functionality.</span>

<span class="sd">    Args:</span>
<span class="sd">        policy_operator (TensorDictModule): a policy operator that reads the hidden variable and returns an action</span>
<span class="sd">        value_operator (TensorDictModule): a value operator, that reads the hidden variable and returns a value</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import (</span>
<span class="sd">        ...      ActorCriticWrapper,</span>
<span class="sd">        ...      ProbabilisticActor,</span>
<span class="sd">        ...      NormalParamWrapper,</span>
<span class="sd">        ...      TanhNormal,</span>
<span class="sd">        ...      ValueOperator,</span>
<span class="sd">        ...  )</span>
<span class="sd">        &gt;&gt;&gt; action_module = TensorDictModule(</span>
<span class="sd">        ...        NormalParamWrapper(torch.nn.Linear(4, 8)),</span>
<span class="sd">        ...        in_keys=[&quot;observation&quot;],</span>
<span class="sd">        ...        out_keys=[&quot;loc&quot;, &quot;scale&quot;],</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; td_module_action = ProbabilisticActor(</span>
<span class="sd">        ...    module=action_module,</span>
<span class="sd">        ...    in_keys=[&quot;loc&quot;, &quot;scale&quot;],</span>
<span class="sd">        ...    distribution_class=TanhNormal,</span>
<span class="sd">        ...    return_log_prob=True,</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; module_value = torch.nn.Linear(4, 1)</span>
<span class="sd">        &gt;&gt;&gt; td_module_value = ValueOperator(</span>
<span class="sd">        ...    module=module_value,</span>
<span class="sd">        ...    in_keys=[&quot;observation&quot;],</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; td_module = ActorCriticWrapper(td_module_action, td_module_value)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(3, 4)}, [3,])</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module.get_policy_operator()(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)  # no value</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module.get_value_operator()(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)  # no action</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="n">value_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">policy_operator</span><span class="p">,</span>
            <span class="n">value_operator</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="ActorCriticWrapper.get_policy_operator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper.html#torchrl.modules.ActorCriticWrapper.get_policy_operator">[docs]</a>    <span class="k">def</span> <span class="nf">get_policy_operator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a standalone policy operator that maps an observation to an action.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="ActorCriticWrapper.get_value_operator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper.html#torchrl.modules.ActorCriticWrapper.get_value_operator">[docs]</a>    <span class="k">def</span> <span class="nf">get_value_operator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a standalone value network operator that maps an observation to a value estimate.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span></div>

    <span class="n">get_policy_head</span> <span class="o">=</span> <span class="n">get_policy_operator</span>
    <span class="n">get_value_head</span> <span class="o">=</span> <span class="n">get_value_operator</span></div>


<div class="viewcode-block" id="DecisionTransformerInferenceWrapper"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper.html#torchrl.modules.DecisionTransformerInferenceWrapper">[docs]</a><span class="k">class</span> <span class="nc">DecisionTransformerInferenceWrapper</span><span class="p">(</span><span class="n">TensorDictModuleWrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Inference Action Wrapper for the Decision Transformer.</span>

<span class="sd">    A wrapper specifically designed for the Decision Transformer, which will mask the</span>
<span class="sd">    input tensordict sequences to the inferece context.</span>
<span class="sd">    The output will be a TensorDict with the same keys as the input, but with only the last</span>
<span class="sd">    action of the predicted action sequence and the last return to go.</span>

<span class="sd">    This module creates returns a modified copy of the tensordict, ie. it does</span>
<span class="sd">    **not** modify the tensordict in-place.</span>

<span class="sd">    .. note:: If the action, observation or reward-to-go key is not standard,</span>
<span class="sd">        the method :meth:`~.set_tensor_keys` should be used, e.g.</span>

<span class="sd">            &gt;&gt;&gt; dt_inference_wrapper.set_tensor_keys(action=&quot;foo&quot;, observation=&quot;bar&quot;, return_to_go=&quot;baz&quot;)</span>

<span class="sd">    The in_keys are the observation, action and return-to-go keys. The out-keys</span>
<span class="sd">    match the in-keys, with the addition of any other out-key from the policy</span>
<span class="sd">    (eg., parameters of the distribution or hidden values).</span>

<span class="sd">    Args:</span>
<span class="sd">        policy (TensorDictModule): The policy module that takes in</span>
<span class="sd">            observations and produces an action value</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        inference_context (int): The number of previous actions that will not be masked in the context.</span>
<span class="sd">            For example for an observation input of shape [batch_size, context, obs_dim] with context=20 and inference_context=5, the first 15 entries</span>
<span class="sd">            of the context will be masked. Defaults to 5.</span>
<span class="sd">        spec (Optional[TensorSpec]): The spec of the input TensorDict. If None, it will be inferred from the policy module.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import (</span>
<span class="sd">        ...      ProbabilisticActor,</span>
<span class="sd">        ...      TanhDelta,</span>
<span class="sd">        ...      DTActor,</span>
<span class="sd">        ...      DecisionTransformerInferenceWrapper,</span>
<span class="sd">        ...  )</span>
<span class="sd">        &gt;&gt;&gt; dtactor = DTActor(state_dim=4, action_dim=2,</span>
<span class="sd">        ...             transformer_config=DTActor.default_config()</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; actor_module = TensorDictModule(</span>
<span class="sd">        ...         dtactor,</span>
<span class="sd">        ...         in_keys=[&quot;observation&quot;, &quot;action&quot;, &quot;return_to_go&quot;],</span>
<span class="sd">        ...         out_keys=[&quot;param&quot;])</span>
<span class="sd">        &gt;&gt;&gt; dist_class = TanhDelta</span>
<span class="sd">        &gt;&gt;&gt; dist_kwargs = {</span>
<span class="sd">        ...     &quot;min&quot;: -1.0,</span>
<span class="sd">        ...     &quot;max&quot;: 1.0,</span>
<span class="sd">        ... }</span>
<span class="sd">        &gt;&gt;&gt; actor = ProbabilisticActor(</span>
<span class="sd">        ...     in_keys=[&quot;param&quot;],</span>
<span class="sd">        ...     out_keys=[&quot;action&quot;],</span>
<span class="sd">        ...     module=actor_module,</span>
<span class="sd">        ...     distribution_class=dist_class,</span>
<span class="sd">        ...     distribution_kwargs=dist_kwargs)</span>
<span class="sd">        &gt;&gt;&gt; inference_actor = DecisionTransformerInferenceWrapper(actor)</span>
<span class="sd">        &gt;&gt;&gt; sequence_length = 20</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(1, sequence_length, 4),</span>
<span class="sd">        ...                 &quot;action&quot;: torch.randn(1, sequence_length, 2),</span>
<span class="sd">        ...                 &quot;return_to_go&quot;: torch.randn(1, sequence_length, 1)}, [1,])</span>
<span class="sd">        &gt;&gt;&gt; result = inference_actor(td)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([1, 2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([1, 20, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                param: Tensor(shape=torch.Size([1, 20, 2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                return_to_go: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([1]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">inference_context</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorSpec</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span> <span class="o">=</span> <span class="s2">&quot;observation&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span> <span class="o">=</span> <span class="s2">&quot;action&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_action_key</span> <span class="o">=</span> <span class="s2">&quot;action&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span> <span class="o">=</span> <span class="s2">&quot;return_to_go&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inference_context</span> <span class="o">=</span> <span class="n">inference_context</span>
        <span class="k">if</span> <span class="n">spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">CompositeSpec</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">spec</span> <span class="o">=</span> <span class="n">CompositeSpec</span><span class="p">({</span><span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">:</span> <span class="n">spec</span><span class="p">},</span> <span class="n">shape</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span> <span class="o">=</span> <span class="n">spec</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="p">,</span> <span class="s2">&quot;_spec&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="o">.</span><span class="n">_spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="p">,</span> <span class="s2">&quot;spec&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span> <span class="o">=</span> <span class="n">CompositeSpec</span><span class="p">({</span><span class="n">key</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">policy</span><span class="o">.</span><span class="n">out_keys</span><span class="p">})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checked</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span><span class="o">.</span><span class="n">union</span><span class="p">(</span>
                <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">}</span>
            <span class="p">),</span>
            <span class="n">key</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="DecisionTransformerInferenceWrapper.set_tensor_keys"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper.html#torchrl.modules.DecisionTransformerInferenceWrapper.set_tensor_keys">[docs]</a>    <span class="k">def</span> <span class="nf">set_tensor_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets the input keys of the module.</span>

<span class="sd">        Keyword Args:</span>
<span class="sd">            observation (NestedKey, optional): The observation key.</span>
<span class="sd">            action (NestedKey, optional): The action key (input to the network).</span>
<span class="sd">            return_to_go (NestedKey, optional): The return_to_go key.</span>
<span class="sd">            out_action (NestedKey, optional): The action key (output of the network).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">observation_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;observation&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">))</span>
        <span class="n">action_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;action&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">))</span>
        <span class="n">out_action_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;out_action&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_action_key</span><span class="p">))</span>
        <span class="n">return_to_go_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span>
            <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;return_to_go&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Got unknown input(s) </span><span class="si">{</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">. Accepted keys are &#39;action&#39;, &#39;return_to_go&#39; and &#39;observation&#39;.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span> <span class="o">=</span> <span class="n">observation_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span> <span class="o">=</span> <span class="n">action_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span> <span class="o">=</span> <span class="n">return_to_go_key</span>
        <span class="k">if</span> <span class="n">out_action_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="o">.</span><span class="n">out_keys</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The value of out_action_key (</span><span class="si">{</span><span class="n">out_action_key</span><span class="si">}</span><span class="s2">) must be &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;within the actor output keys (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="o">.</span><span class="n">out_keys</span><span class="si">}</span><span class="s2">).&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_action_key</span> <span class="o">=</span> <span class="n">out_action_key</span></div>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_check_tensor_dims</span><span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">reward</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Mismatched tensor dimensions. This is not supported yet, file an issue on torchrl&quot;</span>
            <span class="p">)</span>

<div class="viewcode-block" id="DecisionTransformerInferenceWrapper.mask_context"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper.html#torchrl.modules.DecisionTransformerInferenceWrapper.mask_context">[docs]</a>    <span class="k">def</span> <span class="nf">mask_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Mask the context of the input sequences.&quot;&quot;&quot;</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">return_to_go</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_tensor_dims</span><span class="p">(</span><span class="n">return_to_go</span><span class="p">,</span> <span class="n">observation</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>

        <span class="n">observation</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_context</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">action</span><span class="p">[</span>
            <span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_context</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="p">:</span>
        <span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># as we add zeros to the end of the action</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">action</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:],</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="o">*</span><span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">action</span><span class="o">.</span><span class="n">device</span>
                <span class="p">),</span>
            <span class="p">],</span>
            <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">return_to_go</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_context</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">,</span> <span class="n">observation</span><span class="p">)</span>
        <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">,</span> <span class="n">return_to_go</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div>

    <span class="k">def</span> <span class="nf">check_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># an exception will be raised if the action key mismatch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_tensor_keys</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checked</span> <span class="o">=</span> <span class="kc">True</span>

<div class="viewcode-block" id="DecisionTransformerInferenceWrapper.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper.html#torchrl.modules.DecisionTransformerInferenceWrapper.forward">[docs]</a>    <span class="nd">@dispatch</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">checked</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">check_keys</span><span class="p">()</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass of the inference wrapper.&quot;&quot;&quot;</span>
        <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">)</span>
        <span class="c1"># Mask the context of the input sequences</span>
        <span class="n">tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_context</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="c1"># forward pass</span>
        <span class="n">tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="c1"># get last action prediction</span>
        <span class="n">out_action</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_action_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">out_action</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># then time dimension is in the TD&#39;s dimensions, and we must get rid of it</span>
            <span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">out_action</span> <span class="o">=</span> <span class="n">out_action</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_action_key</span><span class="p">,</span> <span class="n">out_action</span><span class="p">)</span>

        <span class="n">out_rtg</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">)</span>
        <span class="n">out_rtg</span> <span class="o">=</span> <span class="n">out_rtg</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">,</span> <span class="n">out_rtg</span><span class="p">)</span>

        <span class="c1"># set unmasked observation</span>
        <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div></div>


<div class="viewcode-block" id="TanhModule"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.TanhModule.html#torchrl.modules.TanhModule">[docs]</a><span class="k">class</span> <span class="nc">TanhModule</span><span class="p">(</span><span class="n">TensorDictModuleBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Tanh module for deterministic policies with bounded action space.</span>

<span class="sd">    This transform is to be used as a TensorDictModule layer to map a network</span>
<span class="sd">    output to a bounded space.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (list of str or tuples of str): the input keys of the module.</span>
<span class="sd">        out_keys (list of str or tuples of str, optional): the output keys of the module.</span>
<span class="sd">            If none is provided, the same keys as in_keys are assumed.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        spec (TensorSpec, optional): if provided, the spec of the output.</span>
<span class="sd">            If a CompositeSpec is provided, its key(s) must match the key(s)</span>
<span class="sd">            in out_keys. Otherwise, the key(s) of out_keys are assumed and the</span>
<span class="sd">            same spec is used for all outputs.</span>
<span class="sd">        low (float, np.ndarray or torch.Tensor): the lower bound of the space.</span>
<span class="sd">            If none is provided and no spec is provided, -1 is assumed. If a</span>
<span class="sd">            spec is provided, the minimum value of the spec will be retrieved.</span>
<span class="sd">        high (float, np.ndarray or torch.Tensor): the higher bound of the space.</span>
<span class="sd">            If none is provided and no spec is provided, 1 is assumed. If a</span>
<span class="sd">            spec is provided, the maximum value of the spec will be retrieved.</span>
<span class="sd">        clamp (bool, optional): if ``True``, the outputs will be clamped to be</span>
<span class="sd">            within the boundaries but at a minimum resolution from them.</span>
<span class="sd">            Defaults to ``False``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; # simplest use case: -1 - 1 boundaries</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; in_keys = [&quot;action&quot;]</span>
<span class="sd">        &gt;&gt;&gt; mod = TanhModule(</span>
<span class="sd">        ...     in_keys=in_keys,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; data = TensorDict({&quot;action&quot;: torch.randn(5) * 10}, [])</span>
<span class="sd">        &gt;&gt;&gt; data = mod(data)</span>
<span class="sd">        &gt;&gt;&gt; data[&#39;action&#39;]</span>
<span class="sd">        tensor([ 1.0000, -0.9944, -1.0000,  1.0000, -1.0000])</span>
<span class="sd">        &gt;&gt;&gt; # low and high can be customized</span>
<span class="sd">        &gt;&gt;&gt; low = -2</span>
<span class="sd">        &gt;&gt;&gt; high = 1</span>
<span class="sd">        &gt;&gt;&gt; mod = TanhModule(</span>
<span class="sd">        ...     in_keys=in_keys,</span>
<span class="sd">        ...     low=low,</span>
<span class="sd">        ...     high=high,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; data = TensorDict({&quot;action&quot;: torch.randn(5) * 10}, [])</span>
<span class="sd">        &gt;&gt;&gt; data = mod(data)</span>
<span class="sd">        &gt;&gt;&gt; data[&#39;action&#39;]</span>
<span class="sd">        tensor([-2.0000,  0.9991,  1.0000, -2.0000, -1.9991])</span>
<span class="sd">        &gt;&gt;&gt; # A spec can be provided</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import BoundedTensorSpec</span>
<span class="sd">        &gt;&gt;&gt; spec = BoundedTensorSpec(low, high, shape=())</span>
<span class="sd">        &gt;&gt;&gt; mod = TanhModule(</span>
<span class="sd">        ...     in_keys=in_keys,</span>
<span class="sd">        ...     low=low,</span>
<span class="sd">        ...     high=high,</span>
<span class="sd">        ...     spec=spec,</span>
<span class="sd">        ...     clamp=False,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; # One can also work with multiple keys</span>
<span class="sd">        &gt;&gt;&gt; in_keys = [&#39;a&#39;, &#39;b&#39;]</span>
<span class="sd">        &gt;&gt;&gt; spec = CompositeSpec(</span>
<span class="sd">        ...     a=BoundedTensorSpec(-3, 0, shape=()),</span>
<span class="sd">        ...     b=BoundedTensorSpec(0, 3, shape=()))</span>
<span class="sd">        &gt;&gt;&gt; mod = TanhModule(</span>
<span class="sd">        ...     in_keys=in_keys,</span>
<span class="sd">        ...     spec=spec,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; data = TensorDict(</span>
<span class="sd">        ...     {&#39;a&#39;: torch.randn(10), &#39;b&#39;: torch.randn(10)}, batch_size=[])</span>
<span class="sd">        &gt;&gt;&gt; data = mod(data)</span>
<span class="sd">        &gt;&gt;&gt; data[&#39;a&#39;]</span>
<span class="sd">        tensor([-2.3020, -1.2299, -2.5418, -0.2989, -2.6849, -1.3169, -2.2690, -0.9649,</span>
<span class="sd">                -2.5686, -2.8602])</span>
<span class="sd">        &gt;&gt;&gt; data[&#39;b&#39;]</span>
<span class="sd">        tensor([2.0315, 2.8455, 2.6027, 2.4746, 1.7843, 2.7782, 0.2111, 0.5115, 1.4687,</span>
<span class="sd">                0.5760])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">spec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">low</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">high</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">clamp</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TanhModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="n">in_keys</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">in_keys</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;in_keys and out_keys should have the same length, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;got in_keys=</span><span class="si">{</span><span class="n">in_keys</span><span class="si">}</span><span class="s2"> and out_keys=</span><span class="si">{</span><span class="n">out_keys</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">=</span> <span class="n">out_keys</span>
        <span class="c1"># action_spec can be a composite spec or not</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">CompositeSpec</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">out_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                    <span class="n">spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># if one spec is present, we assume it is the same for all keys</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">CompositeSpec</span><span class="p">(</span>
                <span class="p">{</span><span class="n">out_key</span><span class="p">:</span> <span class="n">spec</span> <span class="k">for</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">out_keys</span><span class="p">},</span>
            <span class="p">)</span>

        <span class="n">leaf_specs</span> <span class="o">=</span> <span class="p">[</span><span class="n">spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="k">for</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="o">=</span> <span class="n">spec</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">non_trivial</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">out_key</span><span class="p">,</span> <span class="n">leaf_spec</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">out_keys</span><span class="p">,</span> <span class="n">leaf_specs</span><span class="p">):</span>
            <span class="n">_low</span><span class="p">,</span> <span class="n">_high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_low_high</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">leaf_spec</span><span class="p">)</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">out_key</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_key</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">_low&quot;</span><span class="p">,</span> <span class="n">_low</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">_high&quot;</span><span class="p">,</span> <span class="n">_high</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">non_trivial</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">_high</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">or</span> <span class="p">(</span><span class="n">_low</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">_high</span> <span class="o">&lt;</span> <span class="n">_low</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Got high &lt; low in </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clamp</span> <span class="o">=</span> <span class="n">clamp</span>

    <span class="k">def</span> <span class="nf">_make_low_high</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">leaf_spec</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">low</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">leaf_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(())</span>
        <span class="k">elif</span> <span class="n">low</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">low</span> <span class="o">=</span> <span class="n">leaf_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span>
        <span class="k">elif</span> <span class="n">leaf_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">low</span> <span class="o">!=</span> <span class="n">leaf_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The minimum value (</span><span class="si">{</span><span class="n">low</span><span class="si">}</span><span class="s2">) provided to </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2"> does not match the action spec one (</span><span class="si">{</span><span class="n">leaf_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="si">}</span><span class="s2">).&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">low</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">low</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">high</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">leaf_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">high</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(())</span>
        <span class="k">elif</span> <span class="n">high</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">high</span> <span class="o">=</span> <span class="n">leaf_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span>
        <span class="k">elif</span> <span class="n">leaf_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">high</span> <span class="o">!=</span> <span class="n">leaf_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The maximum value (</span><span class="si">{</span><span class="n">high</span><span class="si">}</span><span class="s2">) provided to </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2"> does not match the action spec one (</span><span class="si">{</span><span class="n">leaf_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="si">}</span><span class="s2">).&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">high</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">high</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">high</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span>

<div class="viewcode-block" id="TanhModule.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.TanhModule.html#torchrl.modules.TanhModule.forward">[docs]</a>    <span class="nd">@dispatch</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">]</span>
        <span class="c1"># map</span>
        <span class="k">for</span> <span class="n">out_key</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">out_key</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_key</span><span class="p">)</span>
            <span class="n">low_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">_low&quot;</span>
            <span class="n">high_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">_high&quot;</span>
            <span class="n">low</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">low_key</span><span class="p">)</span>
            <span class="n">high</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">high_key</span><span class="p">)</span>
            <span class="n">feature</span> <span class="o">=</span> <span class="n">feature</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clamp</span><span class="p">:</span>
                <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">feature</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">resolution</span>
                <span class="n">feature</span> <span class="o">=</span> <span class="n">feature</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">+</span> <span class="n">eps</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">eps</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_trivial</span><span class="p">:</span>
                <span class="n">feature</span> <span class="o">=</span> <span class="n">low</span> <span class="o">+</span> <span class="p">(</span><span class="n">high</span> <span class="o">-</span> <span class="n">low</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">feature</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">feature</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div></div>


<div class="viewcode-block" id="LMHeadActorValueOperator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.LMHeadActorValueOperator.html#torchrl.modules.LMHeadActorValueOperator">[docs]</a><span class="k">class</span> <span class="nc">LMHeadActorValueOperator</span><span class="p">(</span><span class="n">ActorValueOperator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Builds an Actor-Value operator from an huggingface-like *LMHeadModel.</span>

<span class="sd">    This method:</span>
<span class="sd">        - takes as input an huggingface-like *LMHeadModel</span>
<span class="sd">        - extracts the final linear layer uses it as a base layer of the actor_head and</span>
<span class="sd">            adds the sampling layer</span>
<span class="sd">        - uses the common transformer as common model</span>
<span class="sd">        - adds a linear critic</span>

<span class="sd">    Args:</span>
<span class="sd">        base_model (nn.Module): a torch model composed by a `.transformer` model and `.lm_head` linear layer</span>

<span class="sd">      .. note:: For more details regarding the class construction, please refer to :class:`~.ActorValueOperator`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_model</span><span class="p">):</span>
        <span class="n">actor_head</span> <span class="o">=</span> <span class="n">base_model</span><span class="o">.</span><span class="n">lm_head</span>
        <span class="n">value_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">actor_head</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">common</span> <span class="o">=</span> <span class="n">TensorDictSequential</span><span class="p">(</span>
            <span class="n">TensorDictModule</span><span class="p">(</span>
                <span class="n">base_model</span><span class="o">.</span><span class="n">transformer</span><span class="p">,</span>
                <span class="n">in_keys</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">},</span>
                <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
            <span class="p">),</span>
            <span class="n">TensorDictModule</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]),</span>
        <span class="p">)</span>
        <span class="n">actor_head</span> <span class="o">=</span> <span class="n">TensorDictModule</span><span class="p">(</span><span class="n">actor_head</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">])</span>
        <span class="n">actor_head</span> <span class="o">=</span> <span class="n">SafeProbabilisticTensorDictSequential</span><span class="p">(</span>
            <span class="n">actor_head</span><span class="p">,</span>
            <span class="n">SafeProbabilisticModule</span><span class="p">(</span>
                <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">],</span>
                <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">],</span>
                <span class="n">distribution_class</span><span class="o">=</span><span class="n">Categorical</span><span class="p">,</span>
                <span class="n">return_log_prob</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="n">value_head</span> <span class="o">=</span> <span class="n">TensorDictModule</span><span class="p">(</span>
            <span class="n">value_head</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;state_value&quot;</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">common</span><span class="p">,</span> <span class="n">actor_head</span><span class="p">,</span> <span class="n">value_head</span><span class="p">)</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>

        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>